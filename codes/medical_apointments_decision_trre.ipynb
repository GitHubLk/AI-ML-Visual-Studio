{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a9403bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e8cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "      PatientId  AppointmentID Gender          ScheduledDay  \\\n",
      "0  2.987250e+13        5642903      F  2016-04-29T18:38:08Z   \n",
      "1  5.589978e+14        5642503      M  2016-04-29T16:08:27Z   \n",
      "2  4.262962e+12        5642549      F  2016-04-29T16:19:04Z   \n",
      "3  8.679512e+11        5642828      F  2016-04-29T17:29:31Z   \n",
      "4  8.841186e+12        5642494      F  2016-04-29T16:07:23Z   \n",
      "\n",
      "         AppointmentDay  Age      Neighbourhood  Scholarship  Hipertension  \\\n",
      "0  2016-04-29T00:00:00Z   62    JARDIM DA PENHA            0             1   \n",
      "1  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             0   \n",
      "2  2016-04-29T00:00:00Z   62      MATA DA PRAIA            0             0   \n",
      "3  2016-04-29T00:00:00Z    8  PONTAL DE CAMBURI            0             0   \n",
      "4  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             1   \n",
      "\n",
      "   Diabetes  Alcoholism  Handcap  SMS_received No-show  \n",
      "0         0           0        0             0      No  \n",
      "1         0           0        0             0      No  \n",
      "2         0           0        0             0      No  \n",
      "3         0           0        0             0      No  \n",
      "4         1           0        0             0      No   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/KaggleV2-May-2016.csv\")\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be61bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "PatientId         0\n",
      "AppointmentID     0\n",
      "Gender            0\n",
      "ScheduledDay      0\n",
      "AppointmentDay    0\n",
      "Age               0\n",
      "Neighbourhood     0\n",
      "Scholarship       0\n",
      "Hipertension      0\n",
      "Diabetes          0\n",
      "Alcoholism        0\n",
      "Handcap           0\n",
      "SMS_received      0\n",
      "No-show           0\n",
      "dtype: int64 \n",
      "\n",
      "Shape after dropping missing values: (110527, 14) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values per column:\")\n",
    "print(df.isna().sum(), \"\\n\")\n",
    "df = df.dropna()\n",
    "print(\"Shape after dropping missing values:\", df.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60054982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature sample:\n",
      "  Gender  Age  Scholarship  Hipertension  Diabetes  Alcoholism  Handcap  \\\n",
      "0      F   62            0             1         0           0        0   \n",
      "1      M   56            0             0         0           0        0   \n",
      "2      F   62            0             0         0           0        0   \n",
      "3      F    8            0             0         0           0        0   \n",
      "4      F   56            0             1         1           0        0   \n",
      "\n",
      "   SMS_received  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0   \n",
      "\n",
      "Target sample:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: No-show, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"Gender\", \"Age\", \"Scholarship\", \"Hipertension\", \"Diabetes\", \"Alcoholism\", \"Handcap\", \"SMS_received\"]\n",
    "df[\"No-show\"] = df[\"No-show\"].map({\"No\": 0, \"Yes\": 1})\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"No-show\"].copy()\n",
    "print(\"Feature sample:\")\n",
    "print(X.head(), \"\\n\")\n",
    "print(\"Target sample:\")\n",
    "print(y.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4868ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"Scholarship\", \"Hipertension\", \"Diabetes\", \"Alcoholism\", \"Handcap\", \"SMS_received\"]\n",
    "categorical_features = [\"Gender\"]\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", StandardScaler(), numeric_features), (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6655a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (88421, 8)\n",
      "Validation shape: (11053, 8)\n",
      "Test shape: (11053, 8) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "print(\"Train shape:\", X_train_full.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
    "best_kernel = None\n",
    "best_val_accuracy_svm = 0.0\n",
    "svm_val_results = {}\n",
    "for k in kernels:\n",
    "    svm_clf = Pipeline(steps=[(\"preprocess\", preprocessor),(\"model\", SVC(kernel=k, C=1.0, random_state=42))])\n",
    "    svm_clf.fit(X_train_full, y_train_full)\n",
    "    y_val_pred_svm = svm_clf.predict(X_val)\n",
    "    val_acc_svm = accuracy_score(y_val, y_val_pred_svm)\n",
    "    svm_val_results[k] = val_acc_svm\n",
    "    print(f\"SVM - Kernel = {k}, Validation Accuracy = {val_acc_svm:.4f}\")\n",
    "    if val_acc_svm > best_val_accuracy_svm:\n",
    "        best_val_accuracy_svm = val_acc_svm\n",
    "        best_kernel = k\n",
    "print(\"\\nBest SVM kernel based on validation:\", best_kernel)\n",
    "print(\"Best SVM validation accuracy:\", best_val_accuracy_svm, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91815277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.concat([X_train_full, X_val])\n",
    "y_train_final = pd.concat([y_train_full, y_val])\n",
    "svm_final = Pipeline(steps=[(\"preprocess\", preprocessor),(\"model\", SVC(kernel=\"linear\", C=1.0, random_state=42))])\n",
    "svm_final.fit(X_train_final, y_train_final)\n",
    "y_test_pred_svm = svm_final.predict(X_test)\n",
    "test_acc_svm = accuracy_score(y_test, y_test_pred_svm)\n",
    "cm_svm = confusion_matrix(y_test, y_test_pred_svm)\n",
    "print(\"=== SVM Final Model (Test Set) ===\")\n",
    "print(f\"Test Accuracy: {test_acc_svm:.4f}\")\n",
    "print(\"Confusion Matrix (rows = true, cols = predicted):\")\n",
    "print(cm_svm, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4d9ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Criterion = gini, Validation Accuracy = 0.7946\n",
      "Decision Tree - Criterion = entropy, Validation Accuracy = 0.7949\n",
      "Decision Tree - Criterion = log_loss, Validation Accuracy = 0.7949\n",
      "\n",
      "Best decision tree criterion based on validation: entropy\n",
      "Best validation accuracy: 0.7948973129467113 \n",
      "\n",
      "=== Decision Tree Final Model (Test Set) ===\n",
      "Test Accuracy: 0.7953\n",
      "Confusion Matrix (rows = true, cols = predicted):\n",
      "[[8765   56]\n",
      " [2206   26]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "criteria = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "best_criterion = None\n",
    "best_val_accuracy = 0.0\n",
    "results_dt = {}\n",
    "\n",
    "for crit in criteria:\n",
    "    # Build a pipeline: preprocessing + classifier\n",
    "    dt_clf = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", DecisionTreeClassifier(criterion=crit, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train on training set\n",
    "    dt_clf.fit(X_train_full, y_train_full)\n",
    "\n",
    "    # Validate on validation set\n",
    "    y_val_pred = dt_clf.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    results_dt[crit] = val_acc\n",
    "\n",
    "    print(f\"Decision Tree - Criterion = {crit}, Validation Accuracy = {val_acc:.4f}\")\n",
    "\n",
    "    # Track best criterion\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        best_criterion = crit\n",
    "\n",
    "print(\"\\nBest decision tree criterion based on validation:\", best_criterion)\n",
    "print(\"Best validation accuracy:\", best_val_accuracy, \"\\n\")\n",
    "\n",
    "# Retrain the final Decision Tree model on TRAIN + VALIDATION using best criterion\n",
    "X_train_final = pd.concat([X_train_full, X_val])\n",
    "y_train_final = pd.concat([y_train_full, y_val])\n",
    "\n",
    "dt_final = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", DecisionTreeClassifier(criterion=best_criterion, random_state=42))\n",
    "])\n",
    "\n",
    "dt_final.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_dt = dt_final.predict(X_test)\n",
    "test_acc_dt = accuracy_score(y_test, y_test_pred_dt)\n",
    "cm_dt = confusion_matrix(y_test, y_test_pred_dt)\n",
    "\n",
    "print(\"=== Decision Tree Final Model (Test Set) ===\")\n",
    "print(f\"Test Accuracy: {test_acc_dt:.4f}\")\n",
    "print(\"Confusion Matrix (rows = true, cols = predicted):\")\n",
    "print(cm_dt, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65acd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - n_estimators = 50, Validation Accuracy = 0.7934\n",
      "Random Forest - n_estimators = 100, Validation Accuracy = 0.7940\n",
      "Random Forest - n_estimators = 200, Validation Accuracy = 0.7940\n",
      "Random Forest - n_estimators = 500, Validation Accuracy = 0.7943\n",
      "\n",
      "Best Random Forest n_estimators based on validation: 500\n",
      "Best validation accuracy: 0.7942640007237854 \n",
      "\n",
      "=== Random Forest Final Model (Test Set) ===\n",
      "Test Accuracy: 0.7952\n",
      "Confusion Matrix (rows = true, cols = predicted):\n",
      "[[8758   63]\n",
      " [2201   31]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators_list = [50, 100, 200, 500]\n",
    "rf_val_results = {}\n",
    "\n",
    "best_rf_n = None\n",
    "best_rf_val_accuracy = 0.0\n",
    "\n",
    "for n in n_estimators_list:\n",
    "    rf_clf = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=n,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Train on training set\n",
    "    rf_clf.fit(X_train_full, y_train_full)\n",
    "\n",
    "    # Validate\n",
    "    y_val_pred_rf = rf_clf.predict(X_val)\n",
    "    val_acc_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "    rf_val_results[n] = val_acc_rf\n",
    "\n",
    "    print(f\"Random Forest - n_estimators = {n}, Validation Accuracy = {val_acc_rf:.4f}\")\n",
    "\n",
    "    # Track best\n",
    "    if val_acc_rf > best_rf_val_accuracy:\n",
    "        best_rf_val_accuracy = val_acc_rf\n",
    "        best_rf_n = n\n",
    "\n",
    "print(\"\\nBest Random Forest n_estimators based on validation:\", best_rf_n)\n",
    "print(\"Best validation accuracy:\", best_rf_val_accuracy, \"\\n\")\n",
    "rf_final = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=best_rf_n,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_final.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_rf = rf_final.predict(X_test)\n",
    "test_acc_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "cm_rf = confusion_matrix(y_test, y_test_pred_rf)\n",
    "\n",
    "print(\"=== Random Forest Final Model (Test Set) ===\")\n",
    "print(f\"Test Accuracy: {test_acc_rf:.4f}\")\n",
    "print(\"Confusion Matrix (rows = true, cols = predicted):\")\n",
    "print(cm_rf, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
